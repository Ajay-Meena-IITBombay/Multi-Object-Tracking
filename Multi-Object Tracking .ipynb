{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from numpy import round\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from munkres import Munkres\n",
    "from math import floor\n",
    "\n",
    "kernel = np.array([[1,1,0,0],[0,1,1,0],[0,1,1,1],[0,0,1,1]],np.uint8)\n",
    "kernel = kernel + np.flip(kernel,0)\n",
    "kernel_e = np.array([[0,0,0,0,0,0,0],[0,0,0,1,1,0,0],[1,1,1,1,1,1,0],[0,0,1,1,0,0,0],[0,0,0,0,0,0,0]],np.uint8)\n",
    "kernel_e = kernel_e + np.flip(kernel_e,0)\n",
    "kernel_d1 = np.array([[0,0,1,0,0],[0,0,1,0,0],[1,1,1,1,1],[0,0,1,0,0],[0,0,1,0,0]],np.uint8)\n",
    "kernel_d2 = np.array([[0,0,0,0,0],[0,0,1,0,0],[0,1,1,1,0],[0,0,1,0,0],[0,0,0,0,0]],np.uint8)\n",
    "\n",
    "\n",
    "\"\"\"Path of Video\"\"\"\n",
    "path_vid = \"C:/Users/dell pc/Desktop/exchange/Sem 8/ELEC431-ADAPTIVE SIGNAL PROCESSING/project/Final reports and code/Project Material(code and test video and result video)/input video.mpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    def __init__(self):\n",
    "        self.dt = 0.005\n",
    "        self.A = array([[1, 0], [0, 1]])  \n",
    "        self.u = zeros((2, 1))  \n",
    "        self.b = array([[0], [255]])  \n",
    "        self.P = diag((3.0, 3.0))  \n",
    "        self.F = array([[1.0, self.dt], [0.0, 1.0]])  \n",
    "        self.Q = eye(self.u.shape[0])  \n",
    "        self.R = eye(self.b.shape[0])  \n",
    "        self.lastResult = array([[0], [255]])\n",
    "\n",
    "    def predict(self):\n",
    "        self.u = np.round(dot(self.F, self.u))\n",
    "        self.P = dot(self.F, dot(self.P, self.F.T)) + self.Q\n",
    "        self.lastResult = self.u  \n",
    "        return self.u\n",
    "\n",
    "    def correct(self, b, flag):\n",
    "        if not flag:  \n",
    "            self.b = self.lastResult\n",
    "        else:  \n",
    "            self.b = b\n",
    "        C = dot(self.A, dot(self.P, self.A.T)) + self.R\n",
    "        K = dot(self.P, dot(self.A.T, linalg.inv(C)))\n",
    "\n",
    "        self.u = round(self.u + dot(K, (self.b - dot(self.A,self.u))))\n",
    "        self.P = self.P - dot(K, dot(C, K.T))\n",
    "        self.lastResult = self.u\n",
    "        return self.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detectors(object):\n",
    "    def __init__(self):\n",
    "        self.fgbg = cv2.createBackgroundSubtractorMOG2(history=250, varThreshold=60,detectShadows=False)\n",
    "\n",
    "    def Detect(self, frame):\n",
    "        \n",
    "        ## Back ground subtraction\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        mask = self.fgbg.apply(gray)\n",
    "        H,W,_ = frame.shape\n",
    "        demag = 30\n",
    "        Win_H = floor(H*demag/100)\n",
    "        Win_W = floor(W*demag/100)\n",
    "        cv2.imshow('Bg Subtraction', mask)\n",
    "        \n",
    "        \n",
    "        ## Morphological Operaations \n",
    "        erosion = cv2.erode(mask,kernel_e,iterations = 1)\n",
    "        dilation = cv2.dilate(erosion,kernel_d1,iterations = 6)\n",
    "        #dilation = cv2.dilate(erosion,kernel_d1,iterations = 6)\n",
    "        \n",
    "        ret, thresh = cv2.threshold(dilation, 250, 255, 0)\n",
    "\n",
    "        _, contours, hierarchy = cv2.findContours(thresh,\n",
    "                                                  cv2.RETR_EXTERNAL,\n",
    "                                                  cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        cv2.imshow('Morphological Operation', thresh)\n",
    "        centers = [] \n",
    "        #r_thresh = 60 #for ball\n",
    "        r_thresh = 14 #fro random walk\n",
    "        #r_thresh = 30 #for town centre\n",
    "        \n",
    "        for cnt in contours:\n",
    "                (x, y), radius = cv2.minEnclosingCircle(cnt)\n",
    "                centeroid = (int(x), int(y))\n",
    "                radius = int(radius)\n",
    "                if (radius > r_thresh):\n",
    "                    cv2.circle(frame, centeroid, radius, (0, 255, 0), 2)\n",
    "                    b = np.array([[x], [y]])\n",
    "                    centers.append(np.round(b))\n",
    "        return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Track(object):\n",
    "\n",
    "    def __init__(self, prediction, trackIdCount):\n",
    "        self.track_id = trackIdCount  \n",
    "        self.KF = KalmanFilter()  \n",
    "        self.prediction = np.asarray(prediction) \n",
    "        self.skipped_frames = 0 \n",
    "        self.trace = [] \n",
    "\n",
    "class Tracker(object):\n",
    "    def __init__(self, dist_thresh, max_frames_to_skip, max_trace_length,\n",
    "                 trackIdCount):\n",
    "        self.dist_thresh = dist_thresh\n",
    "        self.max_frames_to_skip = max_frames_to_skip\n",
    "        self.max_trace_length = max_trace_length\n",
    "        self.tracks = []\n",
    "        self.trackIdCount = trackIdCount\n",
    "\n",
    "    def Update(self, detections):\n",
    "        \n",
    "        if (len(self.tracks) == 0):\n",
    "            for i in range(len(detections)):\n",
    "                track = Track(detections[i], self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "       \n",
    "        N = len(self.tracks)\n",
    "        M = len(detections)\n",
    "        # Finding Cost then applying Hungarian Algorithm\n",
    "        cost = np.zeros(shape=(N, M)) \n",
    "        for i in range(len(self.tracks)):\n",
    "            for j in range(len(detections)):\n",
    "                try:\n",
    "                    diff = self.tracks[i].prediction - detections[j]\n",
    "                    distance = np.sqrt(diff[0][0]*diff[0][0] +\n",
    "                                       diff[1][0]*diff[1][0])\n",
    "                    cost[i][j] = distance\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        cost = (0.5)*cost\n",
    "       \n",
    "        assignment = []\n",
    "        for _ in range(N):\n",
    "            assignment.append(-1)\n",
    "        hungarian = Munkres()\n",
    "\n",
    "        #index = hungarian.compute(cost)\n",
    "        row_ind, col_ind = linear_sum_assignment(cost)\n",
    "        \n",
    "        for i in range(len(row_ind)):\n",
    "            assignment[row_ind[i]] = col_ind[i]\n",
    "\n",
    "        \n",
    "        un_assigned_tracks = []\n",
    "        for i in range(len(assignment)):\n",
    "            if (assignment[i] != -1):\n",
    "               \n",
    "                if (cost[i][assignment[i]] > self.dist_thresh):\n",
    "                    assignment[i] = -1\n",
    "                    un_assigned_tracks.append(i)\n",
    "                pass\n",
    "            else:\n",
    "                self.tracks[i].skipped_frames += 1\n",
    "\n",
    "       \n",
    "        del_tracks = []\n",
    "        for i in range(len(self.tracks)):\n",
    "            if (self.tracks[i].skipped_frames > self.max_frames_to_skip):\n",
    "                del_tracks.append(i)\n",
    "        if len(del_tracks) > 0:  \n",
    "            for id in del_tracks:\n",
    "                if id < len(self.tracks):\n",
    "                    del self.tracks[id]\n",
    "                    del assignment[id]\n",
    "                else:\n",
    "                    print(\"Error in deleting tracks\")\n",
    "\n",
    "       \n",
    "        un_assigned_detects = []\n",
    "        for i in range(len(detections)):\n",
    "                if i not in assignment:\n",
    "                    un_assigned_detects.append(i)\n",
    "\n",
    "        \n",
    "        if(len(un_assigned_detects) != 0):\n",
    "            for i in range(len(un_assigned_detects)):\n",
    "                track = Track(detections[un_assigned_detects[i]],\n",
    "                              self.trackIdCount)\n",
    "                self.trackIdCount += 1\n",
    "                self.tracks.append(track)\n",
    "\n",
    "        for i in range(len(assignment)):\n",
    "            self.tracks[i].KF.predict()\n",
    "\n",
    "            if(assignment[i] != -1):\n",
    "                self.tracks[i].skipped_frames = 0\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct(\n",
    "                                            detections[assignment[i]], 1)\n",
    "            else:\n",
    "                self.tracks[i].prediction = self.tracks[i].KF.correct(\n",
    "                                            np.array([[0], [0]]), 0)\n",
    "\n",
    "            if(len(self.tracks[i].trace) > self.max_trace_length):\n",
    "                for j in range(len(self.tracks[i].trace) -\n",
    "                               self.max_trace_length):\n",
    "                    del self.tracks[i].trace[j]\n",
    "\n",
    "            self.tracks[i].trace.append(self.tracks[i].prediction)\n",
    "            self.tracks[i].KF.lastResult = self.tracks[i].prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_tracking():\n",
    "\n",
    "    detector = Detectors()\n",
    "    tracker = Tracker(60, 20, 50, 1)\n",
    "    track_colors = [(128,0,0), (140, 255, 0), (0, 40, 255), (50, 255, 50),\n",
    "                    (0, 255, 255), (255, 0, 255), (255, 127, 255),\n",
    "                    (127, 0, 255), (127, 0, 127),(0,0,139),(255,20,147),(210,105,30),(112,128,144)]\n",
    "    \n",
    "    \n",
    "    \n",
    "    success, frame = vidcap.read()\n",
    "    H,W,_ = frame.shape\n",
    "    demag = 100\n",
    "\n",
    "    Win_H = floor(H*demag/100)\n",
    "    Win_W = floor(W*demag/100)\n",
    "\n",
    "    cv2.namedWindow('BgSubtraction',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('BgSubtraction',Win_W,Win_H)\n",
    "    cv2.namedWindow('Morphological Operation',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('Morphological Operation', Win_W,Win_H)\n",
    "    \n",
    "    out = cv2.VideoWriter('C:/Users/dell pc/Desktop/outpy.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (Win_W,Win_H))\n",
    "\n",
    "    \n",
    "    while(success):\n",
    "        success, frame = vidcap.read()\n",
    "        orig_frame = copy.copy(frame)\n",
    "        centers = detector.Detect(frame)\n",
    "        if (len(centers) > 0):\n",
    "            tracker.Update(centers)\n",
    "            for i in range(len(tracker.tracks)):\n",
    "                if (len(tracker.tracks[i].trace) > 1):\n",
    "                    for j in range(len(tracker.tracks[i].trace)-1):\n",
    "                        # Draw trace line\n",
    "                        x1 = tracker.tracks[i].trace[j][0][0]\n",
    "                        y1 = tracker.tracks[i].trace[j][1][0]\n",
    "                        x2 = tracker.tracks[i].trace[j+1][0][0]\n",
    "                        y2 = tracker.tracks[i].trace[j+1][1][0]\n",
    "                        clr = tracker.tracks[i].track_id % 13\n",
    "                        cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)),\n",
    "                                 track_colors[clr], 2)\n",
    "            \n",
    "            cv2.namedWindow('Tracking',cv2.WINDOW_NORMAL)\n",
    "            cv2.resizeWindow('Tracking', Win_W,Win_H)\n",
    "            cv2.imshow('Tracking', frame)\n",
    "            out.write(frame)\n",
    "            \n",
    "        cv2.namedWindow('Original',cv2.WINDOW_NORMAL)\n",
    "        cv2.resizeWindow('Original', Win_W,Win_H)\n",
    "        cv2.imshow('Original', orig_frame)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "    vidcap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(3.4.3) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-2f42f95a0d42>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvidcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_vid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstart_tracking\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-5ca48367ee47>\u001b[0m in \u001b[0;36mstart_tracking\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvidcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0morig_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mcenters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mtracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUpdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-62c2ac3c6ff5>\u001b[0m in \u001b[0;36mDetect\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m## Back ground subtraction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgbg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(3.4.3) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:181: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(path_vid)\n",
    "start_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
